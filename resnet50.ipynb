{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d8c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3126149",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN = \"data/train/\"\n",
    "DIR_VAL = \"data/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74238e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = os.listdir(DIR_TRAIN) \n",
    "val_imgs = os.listdir(DIR_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b36c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F2F.0.png', 'F2F.1.png', 'F2F.2.png', 'F2F.3.png', 'F2F.4.png']\n",
      "['F2F.0.png', 'F2F.1.png', 'F2F.2.png', 'F2F.3.png', 'F2F.4.png']\n"
     ]
    }
   ],
   "source": [
    "print(train_imgs[:5])\n",
    "print(val_imgs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe06142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return T.Compose([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomRotation(15),\n",
    "        T.RandomCrop(204),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0, 0, 0),(1, 1, 1))\n",
    "    ])\n",
    "    \n",
    "def get_val_transform():\n",
    "    return T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0, 0, 0),(1, 1, 1))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e8315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFakeDataset(Dataset):\n",
    "    def __init__(self, imgs, mode = \"train\", transforms = None):\n",
    "        super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.imgs[idx]\n",
    "        \n",
    "        \n",
    "        # Training\n",
    "        if self.mode == \"train\":\n",
    "            img = Image.open(DIR_TRAIN + image_name)\n",
    "            img = img.resize((224, 224))\n",
    "            \n",
    "            # Prepare class label\n",
    "            if (image_name.split(\".\")[0] == \"original\"):\n",
    "                label = 1 # It is original\n",
    "            else:\n",
    "                label = 0 # It is fake\n",
    "            \n",
    "            label = torch.tensor(label, dtype = torch.float32)\n",
    "            \n",
    "            ### Apply Transforms on image\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "            return img, label\n",
    "                \n",
    "        # Validation\n",
    "        elif self.mode == \"val\":\n",
    "            img = Image.open(DIR_VAL + image_name)\n",
    "            img = img.resize((224, 224))\n",
    "            \n",
    "            # Prepare class label\n",
    "            if (image_name.split(\".\")[0] == \"original\"):\n",
    "                label = 1 # It is original\n",
    "            else:\n",
    "                label = 0 # It is fake\n",
    "                \n",
    "            label = torch.tensor(label, dtype = torch.float32)\n",
    "            \n",
    "            ### Apply Transforms on image\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "            return img, label\n",
    "        \n",
    "        elif self.mode == \"test\":\n",
    "            \n",
    "            ### Apply Transforms on image\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "            return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e46e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DeepFakeDataset(train_imgs, mode = \"train\", transforms = get_train_transform())\n",
    "val_dataset = DeepFakeDataset(val_imgs, mode = \"val\", transforms = get_val_transform())\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    # num_workers = 4,\n",
    "    batch_size = 16,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    # num_workers = 4,\n",
    "    batch_size = 16,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a0104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a67e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65c2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, trues):\n",
    "    \n",
    "    ### Converting preds to 0 or 1\n",
    "    preds = [1 if preds[i] >= 0.5 else 0 for i in range(len(preds))]\n",
    "    \n",
    "    ### Calculating accuracy by comparing predictions with true labels\n",
    "    acc = [1 if preds[i] == trues[i] else 0 for i in range(len(preds))]\n",
    "    \n",
    "    ### Summing over all correct predictions\n",
    "    acc = np.sum(acc) / len(preds)\n",
    "    \n",
    "    return (acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69b834fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_data_loader):\n",
    "    \n",
    "    ### Local Parameters\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ###Iterating over data loader\n",
    "    for images, labels in train_data_loader:\n",
    "        \n",
    "        #Loading images and labels to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n",
    "        \n",
    "        #Reseting Gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward\n",
    "        preds = model(images)\n",
    "        \n",
    "        #Calculating Loss\n",
    "        _loss = criterion(preds, labels)\n",
    "        loss = _loss.item()\n",
    "        epoch_loss.append(loss)\n",
    "        \n",
    "        #Calculating Accuracy\n",
    "        acc = accuracy(preds, labels)\n",
    "        epoch_acc.append(acc)\n",
    "        \n",
    "        #Backward\n",
    "        _loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    ###Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    ###Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    ###Storing results to logs\n",
    "    train_logs[\"loss\"].append(epoch_loss)\n",
    "    train_logs[\"accuracy\"].append(epoch_acc)\n",
    "    train_logs[\"time\"].append(total_time)\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7af31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(val_data_loader, best_val_acc):\n",
    "    \n",
    "    ### Local Parameters\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ###Iterating over data loader\n",
    "    for images, labels in val_data_loader:\n",
    "        \n",
    "        #Loading images and labels to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n",
    "        \n",
    "        #Forward\n",
    "        preds = model(images)\n",
    "        \n",
    "        #Calculating Loss\n",
    "        _loss = criterion(preds, labels)\n",
    "        loss = _loss.item()\n",
    "        epoch_loss.append(loss)\n",
    "        \n",
    "        #Calculating Accuracy\n",
    "        acc = accuracy(preds, labels)\n",
    "        epoch_acc.append(acc)\n",
    "    \n",
    "    ###Overall Epoch Results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    ###Acc and Loss\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_acc = np.mean(epoch_acc)\n",
    "    \n",
    "    ###Storing results to logs\n",
    "    val_logs[\"loss\"].append(epoch_loss)\n",
    "    val_logs[\"accuracy\"].append(epoch_acc)\n",
    "    val_logs[\"time\"].append(total_time)\n",
    "    \n",
    "    ###Saving best model\n",
    "    if epoch_acc > best_val_acc:\n",
    "        best_val_acc = epoch_acc\n",
    "        torch.save(model.state_dict(),\"resnet50_best.pth\")\n",
    "        \n",
    "    return epoch_loss, epoch_acc, total_time, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "247f0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained = True)\n",
    "\n",
    "# Modifying Head - classifier\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1, bias = True),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2282cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "\n",
    "#Loss Function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Logs - Helpful for plotting after training finishes\n",
    "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
    "\n",
    "# Loading model to device\n",
    "model.to(device)\n",
    "\n",
    "# No of epochs \n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training\n",
      "Epoch 1\n",
      "Loss : 0.5536\n",
      "Acc : 69.7713\n",
      "Time : 154.2331\n",
      "\n",
      "Validating\n",
      "Epoch 1\n",
      "Loss : 0.4479\n",
      "Acc : 77.992\n",
      "Time : 22.141\n",
      "\n",
      "Training\n",
      "Epoch 2\n",
      "Loss : 0.409\n",
      "Acc : 80.2842\n",
      "Time : 137.3524\n",
      "\n",
      "Validating\n",
      "Epoch 2\n",
      "Loss : 0.3542\n",
      "Acc : 84.109\n",
      "Time : 19.0882\n",
      "\n",
      "Training\n",
      "Epoch 3\n",
      "Loss : 0.3391\n",
      "Acc : 84.325\n",
      "Time : 145.8545\n",
      "\n",
      "Validating\n",
      "Epoch 3\n",
      "Loss : 0.3337\n",
      "Acc : 85.4388\n",
      "Time : 24.1803\n",
      "\n",
      "Training\n",
      "Epoch 4\n",
      "Loss : 0.2936\n",
      "Acc : 87.0004\n",
      "Time : 139.4376\n",
      "\n",
      "Validating\n",
      "Epoch 4\n",
      "Loss : 0.2638\n",
      "Acc : 88.7633\n",
      "Time : 19.1897\n",
      "\n",
      "Training\n",
      "Epoch 5\n",
      "Loss : 0.2632\n",
      "Acc : 88.6323\n",
      "Time : 133.058\n",
      "\n",
      "Validating\n",
      "Epoch 5\n",
      "Loss : 0.2928\n",
      "Acc : 86.3032\n",
      "Time : 19.5307\n",
      "\n",
      "Training\n",
      "Epoch 6\n",
      "Loss : 0.2344\n",
      "Acc : 90.2087\n",
      "Time : 134.5653\n",
      "\n",
      "Validating\n",
      "Epoch 6\n",
      "Loss : 0.237\n",
      "Acc : 89.0293\n",
      "Time : 19.12\n",
      "\n",
      "Training\n",
      "Epoch 7\n",
      "Loss : 0.2173\n",
      "Acc : 91.008\n",
      "Time : 132.4732\n",
      "\n",
      "Validating\n",
      "Epoch 7\n",
      "Loss : 0.2106\n",
      "Acc : 91.8883\n",
      "Time : 19.0179\n",
      "\n",
      "Training\n",
      "Epoch 8\n",
      "Loss : 0.1933\n",
      "Acc : 92.1292\n",
      "Time : 133.2204\n",
      "\n",
      "Validating\n",
      "Epoch 8\n",
      "Loss : 0.2491\n",
      "Acc : 90.492\n",
      "Time : 19.055\n",
      "\n",
      "Training\n",
      "Epoch 9\n",
      "Loss : 0.1841\n",
      "Acc : 92.9174\n",
      "Time : 132.8146\n",
      "\n",
      "Validating\n",
      "Epoch 9\n",
      "Loss : 0.2445\n",
      "Acc : 90.2261\n",
      "Time : 19.0989\n",
      "\n",
      "Training\n",
      "Epoch 10\n",
      "Loss : 0.1698\n",
      "Acc : 93.3726\n",
      "Time : 132.5737\n",
      "\n",
      "Validating\n",
      "Epoch 10\n",
      "Loss : 0.1838\n",
      "Acc : 92.4867\n",
      "Time : 19.0793\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "best_val_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    ###Training\n",
    "    loss, acc, _time = train_one_epoch(train_data_loader)\n",
    "    \n",
    "    #Print Epoch Details\n",
    "    print(\"\\nTraining\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    \n",
    "    ###Validation\n",
    "    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, best_val_acc)\n",
    "    \n",
    "    #Print Epoch Details\n",
    "    print(\"\\nValidating\")\n",
    "    print(\"Epoch {}\".format(epoch+1))\n",
    "    print(\"Loss : {}\".format(round(loss, 4)))\n",
    "    print(\"Acc : {}\".format(round(acc, 4)))\n",
    "    print(\"Time : {}\".format(round(_time, 4)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb050e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting Results\n",
    "\n",
    "#Loss\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(np.arange(1, 41, 1), train_logs[\"loss\"], color = 'blue')\n",
    "plt.plot(np.arange(1, 41, 1), val_logs[\"loss\"], color = 'yellow')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "#Accuracy\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(np.arange(1, 41, 1), train_logs[\"accuracy\"], color = 'blue')\n",
    "plt.plot(np.arange(1, 41, 1), val_logs[\"accuracy\"], color = 'yellow')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
