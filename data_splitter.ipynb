{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is given as *manipulated* and *original*. But it should be splitted as training, validation, and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, apart from dividing into 3 datasets, we also need to make sure that the different types of manipulation are evenly divided in the all the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"./data\")\n",
    "os.mkdir(\"./data/train\")\n",
    "os.mkdir(\"./data/val\")\n",
    "os.mkdir(\"./data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulated_paths = glob.glob('./data0/manipulated/*.png')\n",
    "original_paths = glob.glob('./data0/original/*.png')\n",
    "\n",
    "f2f = []\n",
    "eyes = []\n",
    "mouth = []\n",
    "nt = []\n",
    "df = []\n",
    "fs = []\n",
    "\n",
    "manipulated_images_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(manipulated_paths) == 0:\n",
    "    print(\"Could not find imgdb directory!  \" +  \"Make sure you put it here: \" + os.getcwd() )\n",
    "else:\n",
    "    # load image data\n",
    "    for path in manipulated_paths:\n",
    "        name = os.path.split(path)[-1]\n",
    "        manipulation_type = name.split('_')[0]\n",
    "        \n",
    "        if (manipulation_type == 'F2F'):\n",
    "            f2f.append(path)\n",
    "        elif (manipulation_type == 'eyes'):\n",
    "            eyes.append(path)\n",
    "        elif (manipulation_type == 'mouth'):\n",
    "            mouth.append(path)\n",
    "        elif (manipulation_type == 'NT'):\n",
    "            nt.append(path)\n",
    "        elif (manipulation_type == 'DF'):\n",
    "            df.append(path)\n",
    "        elif (manipulation_type == 'FS'):\n",
    "            fs.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulated_images_paths = [f2f, eyes, mouth, nt, df, fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1335\n",
      "1333\n",
      "1333\n",
      "1333\n",
      "1333\n",
      "1333\n"
     ]
    }
   ],
   "source": [
    "for x in manipulated_images_paths:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing images into folders for training, validation, and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be 75% for training, 12.5% for validation, and 12.5% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "counter = 0\n",
    "for x in manipulated_images_paths:\n",
    "    for i in range(1000):\n",
    "        index = random.randint(0, len(x) - 1)\n",
    "        source = x.pop(index)\n",
    "        name = os.path.split(source)[-1]\n",
    "        manipulation_type = name.split('_')[0]\n",
    "        shutil.move(source, f'./data/train/{manipulation_type}.{counter}.png')\n",
    "        counter+=1\n",
    "\n",
    "for i in range(3000):\n",
    "    index = random.randint(0, len(original_paths) - 1)\n",
    "    source = original_paths.pop(index)\n",
    "    shutil.move(source, f'./data/train/original.{counter}.png')\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "counter = 0\n",
    "for x in manipulated_images_paths:\n",
    "    for i in range(166):\n",
    "        index = random.randint(0, len(x) - 1)\n",
    "        source = x.pop(index)\n",
    "        name = os.path.split(source)[-1]\n",
    "        manipulation_type = name.split('_')[0]\n",
    "        shutil.move(source, f'./data/val/{manipulation_type}.{counter}.png')\n",
    "        counter+=1\n",
    "\n",
    "for i in range(500):\n",
    "    index = random.randint(0, len(original_paths) - 1)\n",
    "    source = original_paths.pop(index)\n",
    "    shutil.move(source, f'./data/val/original.{counter}.png')\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "counter = 0\n",
    "for x in manipulated_images_paths:\n",
    "    for i in range(len(x)):\n",
    "        index = random.randint(0, len(x) - 1)\n",
    "        source = x.pop(index)\n",
    "        name = os.path.split(source)[-1]\n",
    "        manipulation_type = name.split('_')[0]\n",
    "        shutil.move(source, f'./data/test/{manipulation_type}.{counter}.png')\n",
    "        counter+=1\n",
    "\n",
    "for i in range(500):\n",
    "    index = random.randint(0, len(original_paths) - 1)\n",
    "    source = original_paths.pop(index)\n",
    "    shutil.move(source, f'./data/test/original.{counter}.png')\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN = './data/train/'\n",
    "DIR_VAL = './data/val/'\n",
    "DIR_TEST = './data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return T.Compose([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomRotation(15),\n",
    "        T.RandomCrop(204),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0, 0, 0),(1, 1, 1))\n",
    "    ])\n",
    "    \n",
    "def get_val_transform():\n",
    "    return T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0, 0, 0),(1, 1, 1))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFakeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imgs, class_to_int, mode = \"train\", transforms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.class_to_int = class_to_int\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_name = self.imgs[idx]\n",
    "        \n",
    "        ### Reading, converting and normalizing image\n",
    "        #img = cv2.imread(DIR_TRAIN + image_name, cv2.IMREAD_COLOR)\n",
    "        #img = cv2.resize(img, (224,224))\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        #img /= 255.\n",
    "        img = Image.open(DIR_TRAIN + image_name)\n",
    "        img = img.resize((224, 224))\n",
    "        \n",
    "        if self.mode == \"train\" or self.mode == \"val\":\n",
    "        \n",
    "            ### Preparing class label\n",
    "            label = self.class_to_int[image_name.split(\".\")[0]]\n",
    "            label = torch.tensor(label, dtype = torch.float32)\n",
    "\n",
    "            ### Apply Transforms on image\n",
    "            img = self.transforms(img)\n",
    "\n",
    "            return img, label\n",
    "        \n",
    "        elif self.mode == \"test\":\n",
    "            \n",
    "            ### Apply Transforms on image\n",
    "            img = self.transforms(img)\n",
    "\n",
    "            return img\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = os.listdir(DIR_TRAIN)\n",
    "val_imgs = os.listdir(DIR_VAL)\n",
    "test_imgs = os.listdir(DIR_TEST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
